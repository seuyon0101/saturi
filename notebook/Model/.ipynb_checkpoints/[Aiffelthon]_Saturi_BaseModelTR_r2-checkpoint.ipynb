{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "401a23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.ticker as ticker\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import time\n",
    "import re\n",
    "import os\n",
    "import io\n",
    "\n",
    "\n",
    "# from tqdm import tqdm_notebook \n",
    "from tqdm.notebook import tqdm \n",
    "import random\n",
    "\n",
    "import sentencepiece as spm\n",
    "from konlpy.tag import Mecab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2076c39f",
   "metadata": {},
   "source": [
    "# Step 1. 데이터 다운로드\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3e2349d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train data load\n",
    "data_dir = os.getenv('HOME')+'/aiffel/data'\n",
    "kor_path = data_dir+\"/korean-english-park.train.ko\"\n",
    "eng_path = data_dir+\"/korean-english-park.train.en\"\n",
    "\n",
    "# test data loading\n",
    "kor_path_test =data_dir+\"/korean-english-park.test.ko\"\n",
    "eng_path_test =data_dir+\"/korean-english-park.test.en\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238d9015",
   "metadata": {},
   "source": [
    "# Step 2. 데이터 정제 및 토큰화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a27c156",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78968"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train 데이터 정제 및 토큰화\n",
    "def clean_corpus(kor_path, eng_path):\n",
    "    with open(eng_path, \"r\") as f: eng = f.read().splitlines()\n",
    "    with open(kor_path, \"r\") as f: kor = f.read().splitlines()\n",
    "\n",
    "    assert len(kor) == len(eng) # kor, eng가 같은 갯수라는 것을 검증받기 위해 적용\n",
    "\n",
    "    cleaned_corpus = list(set(zip(eng, kor)))  # 중복된 데이터 제거\n",
    "    \n",
    "    return cleaned_corpus\n",
    "\n",
    "cleaned_corpus = clean_corpus(eng_path, kor_path)\n",
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcd1ab09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1996"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test 데이터 정제 및 토큰화\n",
    "def clean_corpus_test(kor_path_test, eng_path_test):\n",
    "    with open(eng_path_test, \"r\") as f: eng_test = f.read().splitlines()\n",
    "    with open(kor_path_test, \"r\") as f: kor_test = f.read().splitlines()\n",
    "\n",
    "    assert len(kor_test) == len(eng_test) # kor, eng가 같은 갯수라는 것을 검증받기 위해 적용\n",
    "\n",
    "    cleaned_corpus_test = list(set(zip(eng_test, kor_test)))  # 중복된 데이터 제거\n",
    "    \n",
    "    return cleaned_corpus_test\n",
    "\n",
    "cleaned_corpus_test = clean_corpus_test(eng_path_test, kor_path_test)\n",
    "len(cleaned_corpus_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e03d39f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('그러나 그의 제안은 암살된 총리의 아들인 사드 하리리가 이끄는 서양의 지지를 얻고 있는 여당 의원들에 의해 받아들여지지 않았다.',\n",
       "  'But his offer was rejected by the Western-backed majority led by Saad Hariri, son of the assassinated prime minister.'),\n",
       " ('일본 천황탄생일인 12월 23일과 신년인 1월 2일만 왕궁을 일반에 공개하면 왕실은 먼 곳에 온 방문객의 방문을 맞이한다.',\n",
       "  \"On December 23, the Emperor's birthday, and on January 2, the public is allowed into the grounds of the Imperial Palace, with the royal family greeting visitors from a distance.\"),\n",
       " ('초여름에 메텔사는 디에고 장난감을 포함하여 천8백6십만개의 장난감에 대해 두 번의 대규모 리콜을 행했다.',\n",
       "  'Earlier in the summer the firm made two large-scale recalls that affected 18.6 million toys, including certain Diego toys.'),\n",
       " ('지난 여름부터 유엔 안보리는 부룬디, 아이보리 코스트, 미얀마, 콩고 민주 공화국, 수단, 소말리아 등의 무장 단체들에 제재가 가능하다고 언급했다.',\n",
       "  'Since last summer, groups in Burundi, Ivory Coast, Myanmar, the Democratic Republic of the Congo, Sudan and Somalia have been referred to the U.N. Security Council for possible sanctions.'),\n",
       " ('Newsweek 한글판', 'Teens on MySpace mention sex, violence')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c282e58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('미국 뉴올리언스에서 가장 중요한 산업은 바로 칵테일 산업이다.',\n",
       "  'NEW ORLEANS, Louisiana (CNN) In New Orleans, cocktails are serious business.'),\n",
       " ('버넹키 의장은 미 상원 금융위원회에서 고유가 비용 지출로 하반기 미국 경기가 둔화될 것이라고 전망했다.',\n",
       "  'High energy costs will remain a drag on the U.S. economy for the rest of the year, Bernanke told the Senate Banking Committee Tuesday.'),\n",
       " ('대만 당국은 대만을 강타한 태풍‘갈매기’로 홍수가 발생, 19명이 사망했다고 밝혔다.',\n",
       "  'Taiwanese officials say flash floods triggered by tropical storm Kalmaegi have killed 19 people in Taiwan.'),\n",
       " ('경찰은 그 총격에 대한 목격자들을 확보했으며, 왼쪽 후미등이 고장난 크림색 시보레 아스트로 밴을 수배 중이라고 밝혔다.',\n",
       "  'The sniper has now killed nine people they had witnesses to the shooting and were on the lookout for a cream-colored Chevrolet Astro van with the left rear taillight out.'),\n",
       " ('배설물은 그냥 밑 으로 떨어져 쌓인다.', 'The waste just drops to the ground below.')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_corpus_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "524a1fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_corpus+=cleaned_corpus_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f05c50e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80964"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38a5e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 모든 입력을 소문자로 변환합니다.\n",
    "# 2. 알파벳, 문장부호, 한글만 남기고 모두 제거합니다.\n",
    "# 3. 문장부호 양옆에 공백을 추가합니다.\n",
    "# 4. 문장 앞뒤의 불필요한 공백을 제거합니다.\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "\n",
    "    sentence = sentence.lower() #1\n",
    "    sentence = re.sub(r\"[^a-zA-Z가-힣?.!,]+\", \" \", sentence) #2\n",
    "    sentence = re.sub(r\"([?.!,])\", r\" \\1 \", sentence) #3\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) #4\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d36340c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한글 말뭉치 kor_corpus 와 영문 말뭉치 eng_corpus 를 각각 분리한 후, 정제하여 토큰화를 진행\n",
    "# 최종적으로 ko_tokenizer 과 en_tokenizer 를 얻기\n",
    "# en_tokenizer에는 set_encode_extra_options(\"bos:eos\") 함수를 실행해 타겟 입력이 문장의 시작 토큰과 끝 토큰을 포함할 수 있게\n",
    "# 단어 사전을 매개변수로 받아 원하는 크기의 사전을 정의할 수 있게 합니다. (기본: 20,000)\n",
    "# 학습 후 저장된 model 파일을 SentencePieceProcessor() 클래스에 Load()한 후 반환합니다.\n",
    "# 특수 토큰의 인덱스를 아래와 동일하게 지정합니다.\n",
    "# <PAD> : 0 / <BOS> : 1 / <EOS> : 2 / <UNK> : 3\n",
    "\n",
    "# Sentencepiece를 활용하여 학습한 tokenizer를 생성\n",
    "def generate_tokenizer(corpus, vocab_size, lang=\"en\", pad_id=0, bos_id=1, eos_id=2, unk_id=3):\n",
    "\n",
    "    temp_file = os.getenv('HOME') + f'/aiffel/data/corpus_{lang}.txt'     # corpus를 받아 txt파일로 저장\n",
    "    \n",
    "    with open(temp_file, 'w') as f:\n",
    "        for row in corpus:\n",
    "            f.write(str(row) + '\\n')\n",
    "    \n",
    "    # Sentencepiece를 이용해 \n",
    "    spm.SentencePieceTrainer.Train(\n",
    "        f'--input={temp_file} --pad_id={pad_id} --bos_id={bos_id} --eos_id={eos_id} \\\n",
    "        --unk_id={unk_id} --model_prefix=spm{lang}_r2 --vocab_size={vocab_size}'   # model_r1\n",
    "    )\n",
    "    tokenizer = spm.SentencePieceProcessor()\n",
    "    tokenizer.Load(f'spm{lang}_r2.model') # model_r1\n",
    "\n",
    "    return tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a96226ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/data/corpus_en.txt --pad_id=0 --bos_id=1 --eos_id=2         --unk_id=3 --model_prefix=spmen_r2 --vocab_size=25000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/data/corpus_en.txt\n",
      "  input_format: \n",
      "  model_prefix: spmen_r2\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/data/corpus_en.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 80964 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=10938517\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9909% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=29\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999909\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 80952 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 84011 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 80952\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 45121\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 45121 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=34952 obj=9.85819 num_tokens=84372 num_tokens/piece=2.41394\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=26163 obj=7.99968 num_tokens=84840 num_tokens/piece=3.24275\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spmen_r2.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spmen_r2.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/data/corpus_ko.txt --pad_id=0 --bos_id=1 --eos_id=2         --unk_id=3 --model_prefix=spmko_r2 --vocab_size=25000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/data/corpus_ko.txt\n",
      "  input_format: \n",
      "  model_prefix: spmko_r2\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 25000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 3\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: 0\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/data/corpus_ko.txt\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 80964 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <pad>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=5187141\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9502% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1186\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999502\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 80963 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 161685 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 80963\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 198985\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 198985 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=84518 obj=12.5876 num_tokens=384889 num_tokens/piece=4.55393\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=71479 obj=11.4342 num_tokens=386207 num_tokens/piece=5.40308\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=53603 obj=11.4378 num_tokens=403277 num_tokens/piece=7.5234\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=53586 obj=11.4043 num_tokens=403654 num_tokens/piece=7.53283\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=40189 obj=11.5436 num_tokens=427476 num_tokens/piece=10.6366\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=40189 obj=11.5092 num_tokens=427481 num_tokens/piece=10.6368\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=30141 obj=11.7003 num_tokens=454224 num_tokens/piece=15.07\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=30141 obj=11.6593 num_tokens=454228 num_tokens/piece=15.0701\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=27500 obj=11.7274 num_tokens=462250 num_tokens/piece=16.8091\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=27500 obj=11.7143 num_tokens=462258 num_tokens/piece=16.8094\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: spmko_r2.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: spmko_r2.vocab\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SRC_VOCAB_SIZE = TGT_VOCAB_SIZE = 25000\n",
    "\n",
    "eng_corpus = []\n",
    "kor_corpus = []\n",
    "\n",
    "for pair in cleaned_corpus:\n",
    "    k, e = pair[0], pair[1]\n",
    "    # kor, eng 나눠서 데이터 정제 후 분리\n",
    "    kor_corpus.append(preprocess_sentence(k))\n",
    "    eng_corpus.append(preprocess_sentence(e))\n",
    "\n",
    "en_tokenizer = generate_tokenizer(eng_corpus, SRC_VOCAB_SIZE, \"en\")\n",
    "ko_tokenizer = generate_tokenizer(kor_corpus, TGT_VOCAB_SIZE, \"ko\")\n",
    "ko_tokenizer.set_encode_extra_options(\"bos:eos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0615c658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'prepare to queue but know that it s worth the wait ! '"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7901c420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'줄을 서서 먹어야 하지만 기다려서라도 먹을 만큼 맛있는 아이스크림이라는 사실을 알게 될 것이다 . '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kor_corpus[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9363429b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 611\n",
      "문장의 평균 길이: 135\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# eng_corpus 통계\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "\n",
    "for sen in eng_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(eng_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "#총 max_len의 배열을 만든 후, raw 문장을 돌면서 각 문장별 길이를 sentence_length의 len(sen) 인덱스마다  계속 더해가면서 counting\n",
    "for sen in eng_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8cf9ac11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 331\n",
      "문장의 평균 길이: 64\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAZqUlEQVR4nO3de7RcZX3/8ffHhJtAEy6nKSSpJ9QUG11W8QixUusyCgmIoS7kF+pPo6YrtYUWqxSDdClaL2CtVFoKjYYSLD8uRZFYopICLn/WEjlRCIGIHDGQhEAOJAHECwS+/WM/gzvDuc7Mmdvzea016+x59jN7f2efyWfv/ex9JooIzMwsDy9qdQFmZtY8Dn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M0aTFKvpJA0uYHLfKekmxq4vLslvTFNnyfp3xu47I9I+lKjlmeN5dDvcpKOlfQ9SY9L2iHpvyW9tgHLfY+k7zaixkaStEnSmztpnZIul/S0pCfTY4Okz0iaUukTEVdGxHFjXNYnR+sXES+PiG/XWnNpfW+UtKVq2Z+OiD+td9k2MRz6XUzSbwD/CfwTcDAwHfg48KtW1mVD+mxEHAj0AO8F5gL/LWn/Rq6kkWcf1pkc+t3tdwEi4qqIeDYifhERN0XE+koHSe+TtFHSTknfkvSS0ryQ9H5J90naJeliFX4PuBR4naSfSdqV+u8j6XOSHpT0iKRLJe2X5r1R0hZJH5K0XdI2Se8trWs/Sf8g6YF0VvLd0mvnprOVXZLurAxLjIekF0laJuknkh6TdK2kg9O8ynDM4lT7o5LOraptZdpGGyWdXTm6lfRl4LeBr6dtcXZpte8cankjiYhfRsTtwNuAQyh2AHucWaXfwYVpOz4h6S5Jr5C0FHgncHaq5eup/yZJH5a0HnhK0uQhzk72lXRNOtP4gaTfL73/kPTS0vPLJX0y7ZC+ARye1vczSYerarhI0ttUDCftkvTt9PmpzNsk6SxJ69Pv/RpJ+45lW1ltHPrd7cfAsymwFkg6qDxT0kLgI8DbKY4w/z9wVdUy3gq8FnglcCpwfERsBN4P/E9EHBARU1Pf8yl2NK8CXkpxZvHR0rJ+C5iS2pcAF5dq+hzwGuAPKM5KzgaekzQduBH4ZGo/C/iKpJ5xbou/BE4G/gg4HNgJXFzV51jgSGAe8NFSOH0M6AWOAN4C/N/KCyLiXcCDwElpW3x2DMsbVUQ8CawB/nCI2ccBb6DY1lMofi+PRcRy4EqKs4YDIuKk0mtOA04EpkbE7iGWuRD4D4pt/P+Ar0naa5QanwIWAA+l9R0QEQ+V+0j6XYrP1AcoPmOrKXaQe5e6nQrMB2ZRfM7eM9J6rT4O/S4WEU9QBE8AXwQGJa2SNC11eT/wmYjYmILg08Crykf7wPkRsSsiHgRupQj0F5AkYCnw1xGxI4XWp4FFpW7PAJ+IiGciYjXwM+BISS8C3gecGRFb01nJ9yLiVxQBuzoiVkfEcxGxBugHThjn5ng/cG5EbEnLPQ84RXsOd3w8nQ3dCdwJVI52TwU+HRE7I2ILcNEY1znc8sbqIYoQrvYMcCDwMkDp97dtlGVdFBGbI+IXw8xfFxHXRcQzwOeBfSmGmOr1f4AbI2JNWvbngP0odu7l2h6KiB3A1xnmM2aN4dDvcikQ3hMRM4BXUBzl/mOa/RLgC+m0exewAxDFkXjFw6XpnwMHDLOqHuDFwLrS8r6Z2iseqzrKrCzvUIqQ+ckQy30J8I7KMtNyjwUOG+l9D7Oc60vL2Ag8C0wr9RnuvR4ObC7NK0+PZKzbbjjTKX4ne4iIW4B/pjhT2S5puYrrNyMZrebn50fEc8AWivddr8OBB6qWvZnaPmPWAA79jETEj4DLKcIfin98fxYRU0uP/SLie2NZXNXzR4FfAC8vLWtKRIzlH/CjwC+B3xli3mbgy1U17h8R549hudXLWVC1nH0jYusYXrsNmFF6PrNqfsO/qlbSAcCbKYbcXiAiLoqI1wBzKIZ5/maUWkar8fn3lM68ZlCcaUARxC8u9f2tcSz3IYodbmXZSusay3a3CeDQ72KSXpYunM5Iz2dSjO3elrpcCpwj6eVp/hRJ7xjj4h8BZlTGZtMR3BeBCyX9ZlredEnHj7ag9NrLgM+nC4GTJL1O0j7AvwMnSTo+te+r4qLwjBEWuVfqV3lMTu/1U5WhK0k96ZrGWFxLsZ0OStcYzhhiWxwxxmWNSMXF8NcAX6O47vBvQ/R5raRj0pj7UxQ7zOfqrOU1kt6ettUHKO7wqnxO7gD+JG3/+RTXRSoeAQ5R6fbSKtcCJ0qal+r9UFr2WA4sbAI49Lvbk8AxwFpJT1H8I95A8Q+PiLgeuAC4WtITad6CMS77FuBu4GFJj6a2DwMDwG1pef9FcSFzLM4C7gJupxjSuAB4UURsprjI+BFgkOKI/W8Y+bO7muKso/I4D/gCsAq4SdKTFNvimDHW9gmK4Y6fpvd0HXve9voZ4G/T0NFZY1xmtbNTXY8BVwDrgD9IF0ur/QbFDnYnxdDJY8Dfp3krgDmplq+NY/03UIy/7wTeBbw9jcEDnAmcBOyiuDvo+eWms8ergPvTOvcYEoqIeymuy/wTxRndSRQXvZ8eR23WQPJ/omI2PpL+HFgUEX80amezNuMjfbNRSDpM0utV3Ot/JMWZ0vWtrsusFv7rPLPR7Q38K8V95LuAq4F/aWVBZrXy8I6ZWUY8vGNmlpG2Ht459NBDo7e3t9VlmJl1lHXr1j0aEUN+VUlbh35vby/9/f2tLsPMrKNIemC4eR7eMTPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEPfzCwjDn0zs4w49M3MMuLQNzPLiEO/A/Quu7HVJZhZl3Dom5llxKHfoXz0b2a1cOibmWXEod/hfMRvZuPh0G9zI4W6A9/Mxsuhb2aWEYd+G/ORvJk1mkPfzCwjDv0O4iN/M6uXQ79NDRfwDn4zq4dD38wsIw79DlE+wvfRvpnVyqFvZpaRUUNf0mWStkvaUGr7e0k/krRe0vWSppbmnSNpQNK9ko4vtc9PbQOSljX8nWTOR/9mNhZjOdK/HJhf1bYGeEVEvBL4MXAOgKQ5wCLg5ek1/yJpkqRJwMXAAmAOcFrqa2ZmTTRq6EfEd4AdVW03RcTu9PQ2YEaaXghcHRG/ioifAgPA0ekxEBH3R8TTwNWprzWAj/LNbKwaMab/PuAbaXo6sLk0b0tqG679BSQtldQvqX9wcLAB5ZmZWUVdoS/pXGA3cGVjyoGIWB4RfRHR19PT06jFZsVH/mY2nMm1vlDSe4C3AvMiIlLzVmBmqduM1MYI7WZm1iQ1HelLmg+cDbwtIn5emrUKWCRpH0mzgNnA94HbgdmSZknam+Ji76r6Sjczs/Eayy2bVwH/AxwpaYukJcA/AwcCayTdIelSgIi4G7gWuAf4JnB6RDybLvqeAXwL2Ahcm/paA3lYx8xGM+rwTkScNkTzihH6fwr41BDtq4HV46rOzMwayn+R22Z8tG5mE8mhb2aWEYd+m2j0Eb7PGMxsKA79NuTANrOJ4tBvI40Ie+8wzGwkDn0zs4w49M3MMuLQNzPLiEPfzCwjDv0u1rvsRl/YNbM9OPTbgIPZzJrFoW9mlhGHvplZRhz6LeIhHTNrBYd+BryDMbMKh35GHP5m5tA3M8uIQ9/MLCMOfTOzjDj0W8hj7GbWbA59M7OMOPTNzDIyauhLukzSdkkbSm0HS1oj6b7086DULkkXSRqQtF7SUaXXLE7975O0eGLejpmZjWQsR/qXA/Or2pYBN0fEbODm9BxgATA7PZYCl0CxkwA+BhwDHA18rLKjMDOz5hk19CPiO8COquaFwMo0vRI4udR+RRRuA6ZKOgw4HlgTETsiYiewhhfuSLJRvoDri7lm1ky1julPi4htafphYFqang5sLvXbktqGa38BSUsl9UvqHxwcrLE8MzMbSt0XciMigGhALZXlLY+Ivojo6+npadRiLfGZhVneag39R9KwDenn9tS+FZhZ6jcjtQ3XbmZmTVRr6K8CKnfgLAZuKLW/O93FMxd4PA0DfQs4TtJB6QLucaktOz7SNrNWmjxaB0lXAW8EDpW0heIunPOBayUtAR4ATk3dVwMnAAPAz4H3AkTEDkl/B9ye+n0iIqovDpuZ2QQbNfQj4rRhZs0bom8Apw+znMuAy8ZVnTWMzzDMDPwXuWZmWXHom5llxKGfIQ/1mOXLoW9mlhGHvplZRhz6ZmYZceibmWXEoW9mlhGHfhO1410z7ViTmU2cUf8i17qTw94sTz7SNzPLiEO/CXxUbWbtwqFvZpYRh76ZWUYc+k3iIR4zawcOfTOzjDj0zcwy4tA3M8uIQ9/MLCMOfTOzjDj0zcwy4tA3M8uIQ3+C+f58M2sndYW+pL+WdLekDZKukrSvpFmS1koakHSNpL1T333S84E0v7ch78AawjsnszzUHPqSpgN/BfRFxCuAScAi4ALgwoh4KbATWJJesgTYmdovTP3MzKyJ6h3emQzsJ2ky8GJgG/Am4Lo0fyVwcppemJ6T5s+TpDrXb2Zm41Bz6EfEVuBzwIMUYf84sA7YFRG7U7ctwPQ0PR3YnF67O/U/pHq5kpZK6pfUPzg4WGt5ZmY2hHqGdw6iOHqfBRwO7A/Mr7egiFgeEX0R0dfT01Pv4szMrKSe4Z03Az+NiMGIeAb4KvB6YGoa7gGYAWxN01uBmQBp/hTgsTrWb2Zm41RP6D8IzJX04jQ2Pw+4B7gVOCX1WQzckKZXpeek+bdERNSxfjMzG6d6xvTXUlyQ/QFwV1rWcuDDwAclDVCM2a9IL1kBHJLaPwgsq6NuMzOrgdr5YLuvry/6+/tbXUZdOu3+903nn9jqEsysTpLWRUTfUPP8F7lmZhlx6NseOu3MxMzGx6FvZpYRh/4E8lGzmbUbh/4E6eTA7+TazWxkDn0bkoPfrDs59M3MMjJ59C42Hj5CNrN25iN9M7OMOPTNzDLi0G8gD+2YWbtz6JuZZcShb2aWEYe+jchDVmbdxaFvZpYRh76ZWUYc+mZmGXHoN4jHvs2sEzj0zcwy4tA3M8uIQ9/MLCMOfRuWr1OYdR+Hfp1yCMbeZTdm8T7NclBX6EuaKuk6ST+StFHS6yQdLGmNpPvSz4NSX0m6SNKApPWSjmrMWzAzs7Gq90j/C8A3I+JlwO8DG4FlwM0RMRu4OT0HWADMTo+lwCV1rttawEf8Zp2t5tCXNAV4A7ACICKejohdwEJgZeq2Ejg5TS8ErojCbcBUSYfVun4zMxu/eo70ZwGDwL9J+qGkL0naH5gWEdtSn4eBaWl6OrC59PotqW0PkpZK6pfUPzg4WEd5ZmZWrZ7QnwwcBVwSEa8GnuLXQzkAREQAMZ6FRsTyiOiLiL6enp46yjMzs2r1hP4WYEtErE3Pr6PYCTxSGbZJP7en+VuBmaXXz0htZmbWJDWHfkQ8DGyWdGRqmgfcA6wCFqe2xcANaXoV8O50F89c4PHSMJCZmTXB5Dpf/5fAlZL2Bu4H3kuxI7lW0hLgAeDU1Hc1cAIwAPw89TUzsyaqK/Qj4g6gb4hZ84boG8Dp9azPzMzq47/IbQDfu25mncKhb2aWEYd+HXI7ws/t/Zp1I4e+mVlGHPpmZhlx6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWEYd+jfyHSmbWiRz6Ncg98HN//2adzKFvNXP4m3Ueh77VzeFv1jkc+lYXB75ZZ3HoW00c9madyaE/Tg47M+tkDn0zs4w49M3MMuLQHwcP7ZhZp3Pom5llpO7QlzRJ0g8l/Wd6PkvSWkkDkq6RtHdq3yc9H0jze+tdt5mZjU8jjvTPBDaWnl8AXBgRLwV2AktS+xJgZ2q/MPXrGB7aMbNuUFfoS5oBnAh8KT0X8CbgutRlJXByml6YnpPmz0v9rQt4p2jWGeo90v9H4GzgufT8EGBXROxOz7cA09P0dGAzQJr/eOq/B0lLJfVL6h8cHKyzPDMzK6s59CW9FdgeEesaWA8RsTwi+iKir6enp5GLNjPLXj1H+q8H3iZpE3A1xbDOF4CpkianPjOArWl6KzATIM2fAjxWx/onnIcsxsfby6z91Rz6EXFORMyIiF5gEXBLRLwTuBU4JXVbDNyQplel56T5t0RE1Lp+MzMbv4m4T//DwAclDVCM2a9I7SuAQ1L7B4FlE7BuMzMbweTRu4wuIr4NfDtN3w8cPUSfXwLvaMT6zMysNg0J/W7mcWoz6yb+GgZrOO8ozdqXQ38IDi0z61YOfTOzjDj0raF8lmTW3hz6NiEc/mbtyaFvZpYRh76ZWUYc+mZmGXHom5llxKFvZpYRh76ZWUYc+mZmGXHo24Ty/fpm7cWhbxPGgW/Wfhz6VRxUjedtatY+HPpmZhlx6JuZZcShb2aWEYf+MDwO3ViV7entatZaDn0zs4w49K0lfMRv1hoOfTOzjNQc+pJmSrpV0j2S7pZ0Zmo/WNIaSfelnweldkm6SNKApPWSjmrUm7DO4KN7s9ar50h/N/ChiJgDzAVOlzQHWAbcHBGzgZvTc4AFwOz0WApcUse6rYM5/M1ap+bQj4htEfGDNP0ksBGYDiwEVqZuK4GT0/RC4Ioo3AZMlXRYreufCA4jM+t2DRnTl9QLvBpYC0yLiG1p1sPAtDQ9HdhcetmW1Fa9rKWS+iX1Dw4ONqI8MzNL6g59SQcAXwE+EBFPlOdFRAAxnuVFxPKI6IuIvp6ennrLMzOzkrpCX9JeFIF/ZUR8NTU/Uhm2ST+3p/atwMzSy2ektpbxcE5refubNV89d+8IWAFsjIjPl2atAhan6cXADaX2d6e7eOYCj5eGgSxTDn6z5qrnSP/1wLuAN0m6Iz1OAM4H3iLpPuDN6TnAauB+YAD4IvAXdazbupR3AmYTa3KtL4yI7wIaZva8IfoHcHqt67Pu1rvsRjadf2KryzDrev6LXDOzjDj0zcwy4tC3lvM4vlnzOPStrXmHYNZYDn0zs4w49BMfUbae/3cts4nn0Le25OA3mxgOfTOzjDj0re35qN+scRz61hEc/GaN4dC3tuWgN2u8rELfIWJmucsi9EcLe+8MOoN/T2b1yyL0h+IA6Uz+vZnVJ9vQNzPLUc3fp2/WKtVH+/4efrOxyzL0PUTQXbwTMBu77Id3vAMws5xkH/rWfap35N6xm/1alsM7lgeHvdkLqfj/yttTX19f9Pf3170c/+M38Fi/5UPSuojoG2qeh3csG73LbtzjO/t9MGA5cuhbdsphX/0ft1R2Bt4hWLdqeuhLmi/pXkkDkpY1e/1m1Ub6H7uqdwLV02adpqmhL2kScDGwAJgDnCZpTjNrMBurke4CGu9OwDsIaxfNvnvnaGAgIu4HkHQ1sBC4Z6JW6H9s1gxjPfofy+exfMG50n/T+Se+YLrSrzw91OvGa6jlWfdo6t07kk4B5kfEn6bn7wKOiYgzSn2WAkvT0yOBe+tY5aHAo3W8vlVcd3O57uZy3RPvJRHRM9SMtrtPPyKWA8sbsSxJ/cPdttTOXHdzue7mct2t1ewLuVuBmaXnM1KbmZk1QbND/3ZgtqRZkvYGFgGrmlyDmVm2mjq8ExG7JZ0BfAuYBFwWEXdP4CobMkzUAq67uVx3c7nuFmrrr2EwM7PG8l/kmpllxKFvZpaRrg39Tvq6B0mbJN0l6Q5J/antYElrJN2Xfh7UBnVeJmm7pA2ltiHrVOGitP3XSzqqzeo+T9LWtM3vkHRCad45qe57JR3foppnSrpV0j2S7pZ0Zmpv6+09Qt3tvr33lfR9SXemuj+e2mdJWpvquybdgIKkfdLzgTS/txV11yQiuu5BcZH4J8ARwN7AncCcVtc1Qr2bgEOr2j4LLEvTy4AL2qDONwBHARtGqxM4AfgGIGAusLbN6j4POGuIvnPS52UfYFb6HE1qQc2HAUel6QOBH6fa2np7j1B3u29vAQek6b2AtWk7XgssSu2XAn+epv8CuDRNLwKuacX2ruXRrUf6z3/dQ0Q8DVS+7qGTLARWpumVwMmtK6UQEd8BdlQ1D1fnQuCKKNwGTJV0WFMKrTJM3cNZCFwdEb+KiJ8CAxSfp6aKiG0R8YM0/SSwEZhOm2/vEeoeTrts74iIn6Wne6VHAG8Crkvt1du78nu4DpgnSc2ptj7dGvrTgc2l51sY+YPXagHcJGld+hoKgGkRsS1NPwxMa01poxquzk74HZyRhkIuKw2ftV3daejg1RRHnx2zvavqhjbf3pImSboD2A6soTjr2BURu4eo7fm60/zHgUOaWnCNujX0O82xEXEUxbePni7pDeWZUZxDtv29tZ1SZ3IJ8DvAq4BtwD+0tJphSDoA+ArwgYh4ojyvnbf3EHW3/faOiGcj4lUU3xRwNPCy1lY0Mbo19Dvq6x4iYmv6uR24nuID90jl9Dz93N66Ckc0XJ1t/TuIiEfSP/LngC/y6yGFtqlb0l4UwXllRHw1Nbf99h6q7k7Y3hURsQu4FXgdxTBZ5Y9Yy7U9X3eaPwV4rLmV1qZbQ79jvu5B0v6SDqxMA8cBGyjqXZy6LQZuaE2FoxquzlXAu9NdJXOBx0vDEi1XNd79xxTbHIq6F6W7M2YBs4Hvt6A+ASuAjRHx+dKstt7ew9XdAdu7R9LUNL0f8BaK6xG3AqekbtXbu/J7OAW4JZ15tb9WX0meqAfF3Qw/phiXO7fV9YxQ5xEUdy/cCdxdqZVifPBm4D7gv4CD26DWqyhOzZ+hGN9cMlydFHdDXJy2/11AX5vV/eVU13qKf8CHlfqfm+q+F1jQopqPpRi6WQ/ckR4ntPv2HqHudt/erwR+mOrbAHw0tR9BsRMaAP4D2Ce175ueD6T5R7Tq8z3eh7+GwcwsI906vGNmZkNw6JuZZcShb2aWEYe+mVlGHPpmZhlx6JuZZcShb2aWkf8FAXho7ILaNlEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# kor_corpus 통계\n",
    "\n",
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "\n",
    "for sen in kor_corpus:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(kor_corpus))\n",
    "\n",
    "sentence_length = np.zeros((max_len), dtype=int)\n",
    "\n",
    "#총 max_len의 배열을 만든 후, raw 문장을 돌면서 각 문장별 길이를 sentence_length의 len(sen) 인덱스마다  계속 더해가면서 counting\n",
    "for sen in kor_corpus:\n",
    "    sentence_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), sentence_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "434dc6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_tokens = np.mean(num_tokens) + 2.5 * np.std(num_tokens)\n",
    "# maxlen = int(max_tokens)\n",
    "# print('pad_sequences maxlen : ', maxlen)\n",
    "# print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)*100}%가 maxlen 설정값 이내에 포함됩니다.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c72efe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cbba95fb68f488d8e601b2ffd31902f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/80964 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 토크나이저를 활용해 토큰의 길이가 50 이하인 데이터를 선별하여 src_corpus 와 tgt_corpus 를 각각 구축하고, 텐서 enc_train 과 dec_train 으로 변환\n",
    "src_corpus = [] #영어\n",
    "tgt_corpus = [] #한글\n",
    "\n",
    "assert len(kor_corpus) == len(eng_corpus)\n",
    "\n",
    "# 토큰의 길이가 xxx 이하인 문장만 남깁니다. \n",
    "for idx in tqdm(range(len(kor_corpus))):\n",
    "    src = en_tokenizer.EncodeAsIds(eng_corpus[idx])\n",
    "    tgt = ko_tokenizer.EncodeAsIds(kor_corpus[idx])\n",
    "    \n",
    "    if len(src) <= 120 and len(tgt) <= 100: \n",
    "        src_corpus.append(src)\n",
    "        tgt_corpus.append(tgt)\n",
    "\n",
    "# 패딩처리를 완료하여 학습용 데이터를 완성합니다. \n",
    "enc_data = tf.keras.preprocessing.sequence.pad_sequences(src_corpus, padding='post')\n",
    "dec_data = tf.keras.preprocessing.sequence.pad_sequences(tgt_corpus, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afe5e272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 훈련 데이터와 검증 데이터로 분리하기\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(enc_data, dec_data, test_size=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d795f715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(76914, 116)\n",
      "(76914, 95)\n",
      "(4049, 116)\n",
      "(4049, 95)\n"
     ]
    }
   ],
   "source": [
    "# enc, dec 의 seq_length는 달라도 상관없음.\n",
    "print(enc_train.shape)\n",
    "print(dec_train.shape)\n",
    "print(enc_val.shape)\n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b20f8395",
   "metadata": {},
   "source": [
    "# Step 3. 모델설계"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d978273",
   "metadata": {},
   "source": [
    "## Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e811e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos - 단어가 위치한 Time-step(각각의 토큰의 위치정보값이며 정수값을 의미)\n",
    "# d_model - 모델의 Embedding 차원 수\n",
    "# i - Encoding차원의 index\n",
    "\n",
    "def positional_encoding(pos, d_model):\n",
    "    def cal_angle(position, i):\n",
    "        return position / np.power(10000, int(i)/d_model)  # np.power(a,b) > a^b(제곱)\n",
    "    \n",
    "    def get_posi_angle_vec(position):\n",
    "        return [cal_angle(position, i) for i in range(d_model)]\n",
    "    \n",
    "    sinusoid_table = np.array([get_posi_angle_vec(pos_i) for pos_i in range(pos)])\n",
    "    \n",
    "    # 배열의 짝수 인덱스(2i)에는 사인 함수 적용\n",
    "    sinusoid_table[:, 0::2] = np.sin(sinusoid_table[:, 0::2])\n",
    "    # 배열의 홀수 인덱스(2i+1)에는 코사인 함수 적용\n",
    "    sinusoid_table[:, 1::2] = np.cos(sinusoid_table[:, 1::2])\n",
    "    \n",
    "    return sinusoid_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a8ae7e",
   "metadata": {},
   "source": [
    "## Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f4089b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        \n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        self.W_q = tf.keras.layers.Dense(d_model)  # Linear Layer\n",
    "        self.W_k = tf.keras.layers.Dense(d_model)\n",
    "        self.W_v = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "        self.linear = tf.keras.layers.Dense(d_model)\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask):\n",
    "        d_k = tf.cast(K.shape[-1], tf.float32)\n",
    "        \n",
    "        # Scaled QK 값 구하기\n",
    "        QK = tf.matmul(Q, K, transpose_b=True)\n",
    "        scaled_qk = QK / tf.math.sqrt(d_k)\n",
    "        \n",
    "        if mask is not None:\n",
    "            scaled_qk += (mask * -1e9)\n",
    "        \n",
    "        # 1. Attention Weights 값 구하기 -> attentions\n",
    "        attentions = tf.nn.softmax(scaled_qk, axis=-1)\n",
    "        # 2. Attention 값을 V에 곱하기 -> out\n",
    "        out = tf.matmul(attentions, V)\n",
    "        return out, attentions\n",
    "    \n",
    "    def split_heads(self, x):\n",
    "        \"\"\"\n",
    "        Embedding된 입력을 head의 수로 분할하는 함수\n",
    "        \n",
    "        x: [ batch x length x emb ]\n",
    "        return: [ batch x length x heads x self.depth ]\n",
    "        \"\"\"\n",
    "        bsz = x.shape[0]\n",
    "        split_x = tf.reshape(x, (bsz, -1, self.num_heads, self.depth))\n",
    "        split_x = tf.transpose(split_x, perm=[0, 2, 1, 3])\n",
    "        return split_x\n",
    "    \n",
    "    def combine_heads(self, x):\n",
    "        \"\"\"\n",
    "        분할된 Embedding을 하나로 결합하는 함수\n",
    "        \n",
    "        x: [ batch x length x heads x self.depth ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        bsz = x.shape[0]\n",
    "        combined_x = tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "        combined_x = tf.reshape(combined_x, (bsz, -1, self.d_model))\n",
    "        return combined_x\n",
    "    \n",
    "    def call(self, Q, K, V, mask):\n",
    "        \"\"\"\n",
    "        Step 1: Linear_in(Q, K, V) -> WQ, WK, WV\n",
    "        Step 2: Split Heads(WQ, WK, WV) -> WQ_split, WK_split, WV_split\n",
    "        Step 3: Scaled Dot Product Attention(WQ_split, WK_split, WV_split)\n",
    "                 -> out, attention_weights\n",
    "        Step 4: Combine Heads(out) -> out\n",
    "        Step 5: Linear_out(out) -> out\n",
    "        \"\"\"\n",
    "        WQ = self.W_q(Q)\n",
    "        WK = self.W_k(K)\n",
    "        WV = self.W_v(V)\n",
    "        \n",
    "        WQ_splits = self.split_heads(WQ)\n",
    "        WK_splits = self.split_heads(WK)\n",
    "        WV_splits = self.split_heads(WV)\n",
    "        \n",
    "        out, attention_weights = self.scaled_dot_product_attention(\n",
    "            WQ_splits, WK_splits, WV_splits, mask\n",
    "        )\n",
    "        \n",
    "        out = self.combine_heads(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a96beee6",
   "metadata": {},
   "source": [
    "## Position-wise Feed-Forward Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "adb68aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "슝=3\n"
     ]
    }
   ],
   "source": [
    "class PoswiseFeedForwardNet(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PoswiseFeedForwardNet, self).__init__()\n",
    "        self.w_1 = tf.keras.layers.Dense(d_ff, activation='relu')\n",
    "        self.w_2 = tf.keras.layers.Dense(d_model)\n",
    "\n",
    "    def call(self, x):\n",
    "        out = self.w_1(x)\n",
    "        out = self.w_2(out)\n",
    "            \n",
    "        return out\n",
    "\n",
    "print(\"슝=3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def6c4ee",
   "metadata": {},
   "source": [
    "d_ff 는 논문의 설명대로라면 2048 일 거고, d_model 은 512  [ batch x length x d_model ] 의 입력을 받아 w_1 이 2048차원으로 매핑하고 활성함수 ReLU를 적용한 후, 다시 w_2 를 통해 512차원으로 되돌리는 과정"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a16d1c",
   "metadata": {},
   "source": [
    "## Encoder 레이어 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc9893e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.enc_self_attn = MultiHeadAttention(d_model, n_heads)\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "        \n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        \n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        # Multi-Head Attention\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        out, enc_attn = self.enc_self_attn(out, out, out, mask)\n",
    "        out = self.do(out)\n",
    "        out += residual*1 \n",
    "        \n",
    "        # Position-Wise Feed Forward Network\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual*1 \n",
    "        \n",
    "        return out, enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec3369e",
   "metadata": {},
   "source": [
    "## Decoder 레이어 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7ab3637c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.dec_self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.enc_dec_attn = MultiHeadAttention(d_model, num_heads)\n",
    "\n",
    "        self.ffn = PoswiseFeedForwardNet(d_model, d_ff)\n",
    "\n",
    "        self.norm_1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.norm_3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        # Masked Multi-Head Attention\n",
    "        residual = x\n",
    "        out = self.norm_1(x)\n",
    "        #out, dec_attn = self.dec_self_attn(out, out, out, causality_mask)\n",
    "        out, dec_attn = self.dec_self_attn(out, out, out, padding_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "        \n",
    "        # Multi-Head Attention\n",
    "        residual = out\n",
    "        out = self.norm_2(out)\n",
    "        #out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, padding_mask)\n",
    "        out, dec_enc_attn = self.enc_dec_attn(out, enc_out, enc_out, causality_mask)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        # Position-Wise Feed Forward Network\n",
    "        residual = out\n",
    "        out = self.norm_3(out)\n",
    "        out = self.ffn(out)\n",
    "        out = self.do(out)\n",
    "        out += residual\n",
    "\n",
    "        return out, dec_attn, dec_enc_attn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e96a72",
   "metadata": {},
   "source": [
    "## Encoder와 Decoder 클래스를 정의\n",
    "EncodeLayer 와 DecoderLayer 를 모두 정의했으니 이를 조립하는 것은 어렵지 않겠죠? 이를 이용해 Encoder와 Decoder 클래스를 정의합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da45f9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.enc_layers = [EncoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "    def call(self, x, mask):\n",
    "        out = x\n",
    "        enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, enc_attn = self.enc_layers[i](out, mask)\n",
    "            enc_attns.append(enc_attn)\n",
    "            \n",
    "        return out, enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9ca3d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, dropout):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.dec_layers = [DecoderLayer(d_model, n_heads, d_ff, dropout) for _ in range(n_layers)]\n",
    "        \n",
    "    def call(self, x, enc_out, causality_mask, padding_mask):\n",
    "        out = x\n",
    "        dec_attns = list()\n",
    "        dec_enc_attns = list()\n",
    "        for i in range(self.n_layers):\n",
    "            out, dec_attn, dec_enc_attn = self.dec_layers[i](out, enc_out, causality_mask, padding_mask)\n",
    "            dec_attns.append(dec_attn)\n",
    "            dec_enc_attns.append(dec_enc_attn)\n",
    "        \n",
    "        return out, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12aa219c",
   "metadata": {},
   "source": [
    "## Transformer 완성하기\n",
    "\n",
    "    shared 변수를 매개변수로 받아 True 일 경우 Decoder Embedding과 출력층 Linear의 Weight를 공유\n",
    "    Weight가 공유될 경우 Embedding 값에 sqrt(d_model) 을 곱해줘야 하는 것, (참고: tf.keras.layers.Layer.set_weights())\n",
    "\n",
    "    우리가 정의한 positional_encoding 의 반환값 형태는 [ Length x d_model ] 인데, 이를 더해 줄 Embedding 값 형태가 [ Batch x Length x d_model ] 이라서 연산이 불가능합니다. 연산이 가능하도록 수정 (참고: tf.expand_dims(), np.newaxis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15e88b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, n_layers, d_model, n_heads, d_ff, src_vocab_size, tgt_vocab_size,\n",
    "                 pos_len, dropout=0.2, shared=True):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.d_model = tf.cast(d_model, tf.float32)\n",
    "        \n",
    "        # 1. Embedding Layer 정의\n",
    "        self.enc_emb = tf.keras.layers.Embedding(src_vocab_size, d_model)\n",
    "        self.dec_emb = tf.keras.layers.Embedding(tgt_vocab_size, d_model)\n",
    "        \n",
    "        # 2. Positional Encoding 정의\n",
    "        self.pos_encoding = positional_encoding(pos_len, d_model)\n",
    "        # 6. Dropout 정의\n",
    "        self.do = tf.keras.layers.Dropout(dropout)\n",
    "        \n",
    "        # 3. Encoder / Decoder 정의\n",
    "        self.encoder = Encoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        self.decoder = Decoder(n_layers, d_model, n_heads, d_ff, dropout)\n",
    "        \n",
    "        # 4. Output Linear 정의\n",
    "        self.fc = tf.keras.layers.Dense(tgt_vocab_size)\n",
    "        \n",
    "        # 5. Shared Weights\n",
    "        self.shared = shared\n",
    "        \n",
    "        if shared:\n",
    "            self.fc.set_weights(tf.transpose(self.dec_emb.weights))\n",
    "        \n",
    "        \n",
    "    def embedding(self, emb, x):\n",
    "        \"\"\"\n",
    "        입력된 정수 배열을 Embedding + Pos Encoding\n",
    "        + Shared일 경우 Scaling 작업 포함\n",
    "\n",
    "        x: [ batch x length ]\n",
    "        return: [ batch x length x emb ]\n",
    "        \"\"\"\n",
    "        seq_len = x.shape[1]\n",
    "        out = emb(x)\n",
    "        \n",
    "        if self.shared:\n",
    "            out *= tf.math.sqrt(self.d_model)\n",
    "        \n",
    "        out += self.pos_encoding[np.newaxis, ...][:, :seq_len, :]\n",
    "        out = self.do(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    def call(self, enc_in, dec_in, enc_mask, causality_mask, dec_mask):\n",
    "        # Step 1: Embedding(enc_in, dec_in) -> enc_in, dec_in\n",
    "        enc_in = self.embedding(self.enc_emb, enc_in)\n",
    "        dec_in = self.embedding(self.dec_emb, dec_in)\n",
    "        \n",
    "        # Step 2: Encoder(enc_in, enc_mask) -> enc_out, enc_attns\n",
    "        enc_out, enc_attns = self.encoder(enc_in, enc_mask)\n",
    "\n",
    "        # Step 3: Decoder(dec_in, enc_out, mask) -> dec_out, dec_attns, dec_enc_attns\n",
    "        dec_out, dec_attns, dec_enc_attns = self.decoder(dec_in, enc_out, causality_mask, dec_mask)\n",
    "        \n",
    "        # Step 4: Out Linear(dec_out) -> logits\n",
    "        logits = self.fc(dec_out)\n",
    "        \n",
    "        return logits, enc_attns, dec_attns, dec_enc_attns\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b415f0b8",
   "metadata": {},
   "source": [
    "## Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "63068b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention을 할 때에 <PAD> 토큰에도 Attention을 주는 것을 방지해 주는 역할\n",
    "def generate_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "def generate_causality_mask(src_len, tgt_len):\n",
    "    mask = 1 - np.cumsum(np.eye(src_len, tgt_len), 0)\n",
    "    return tf.cast(mask, tf.float32)\n",
    "\n",
    "def generate_masks(src, tgt):\n",
    "    enc_mask = generate_padding_mask(src)\n",
    "    dec_mask = generate_padding_mask(tgt)\n",
    "\n",
    "    dec_enc_causality_mask = generate_causality_mask(tgt.shape[1], src.shape[1])\n",
    "    dec_enc_mask = tf.maximum(enc_mask, dec_enc_causality_mask)\n",
    "\n",
    "    dec_causality_mask = generate_causality_mask(tgt.shape[1], tgt.shape[1])\n",
    "    dec_mask = tf.maximum(dec_mask, dec_causality_mask)\n",
    "\n",
    "    return enc_mask, dec_enc_mask, dec_mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a414c9a6",
   "metadata": {},
   "source": [
    "# Step 4. 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "27ceafc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = Transformer(\n",
    "    n_layers=2,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_ff=2048,\n",
    "    src_vocab_size=SRC_VOCAB_SIZE,\n",
    "    tgt_vocab_size=TGT_VOCAB_SIZE,\n",
    "    pos_len=200,\n",
    "    dropout=0.1,\n",
    "    shared=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8f5f43",
   "metadata": {},
   "source": [
    "##  Learning Rate Scheduler를 선언하고, 이를 포함하는 Adam Optimizer를 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "487a1fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningRateScheduler(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
    "    def __init__(self, d_model, warmup_steps=4000):\n",
    "        super(LearningRateScheduler, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.warmup_steps = warmup_steps\n",
    "    \n",
    "    def __call__(self, step):\n",
    "        arg1 = step ** -0.5\n",
    "        arg2 = step * (self.warmup_steps ** -1.5)\n",
    "        \n",
    "        return (self.d_model ** -0.5) * tf.math.minimum(arg1, arg2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4a714f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = LearningRateScheduler(512)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed41c4",
   "metadata": {},
   "source": [
    "## Loss 함수를 정의\n",
    "    Sequence-to-sequence 모델에서 사용했던 Loss와 유사하되, Masking 되지 않은 입력의 개수로 Scaling하는 과정을 추가. (트랜스포머가 모든 입력에 대한 Loss를 한 번에 구하기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cd1c67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss 함수 정의\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
    "\n",
    "def loss_function(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    # Masking 되지 않은 입력의 개수로 Scaling하는 과정\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "\n",
    "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1417744",
   "metadata": {},
   "source": [
    "## train_step 함수를 정의\n",
    "    입력 데이터에 알맞은 Mask를 생성하고, 이를 모델에 전달하여 연산에서 사용할 수 있게 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b245aa6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(src, tgt, model, optimizer):\n",
    "    gold = tgt[:, 1:]\n",
    "        \n",
    "    enc_mask, dec_enc_mask, dec_mask = generate_masks(src, tgt)\n",
    "\n",
    "    # 계산된 loss에 tf.GradientTape()를 적용해 학습을 진행합니다.\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(src, tgt, enc_mask, dec_enc_mask, dec_mask)\n",
    "        loss = loss_function(gold, predictions[:, :-1])\n",
    "\n",
    "    # 최종적으로 optimizer.apply_gradients()가 사용됩니다. \n",
    "    gradients = tape.gradient(loss, model.trainable_variables)    \n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    \n",
    "    return loss, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "625829e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step = tf.Variable(1), optimizer = optimizer , transformer = transformer)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts_gd12_r1',max_to_keep=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7c593c",
   "metadata": {},
   "source": [
    "## Attention 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "17f605f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attention 시각화 함수\n",
    "def visualize_attention(src, tgt, enc_attns, dec_attns, dec_enc_attns):\n",
    "    def draw(data, ax, x=\"auto\", y=\"auto\"):\n",
    "        import seaborn\n",
    "        seaborn.heatmap(data, \n",
    "                        square=True,\n",
    "                        vmin=0.0, vmax=1.0, \n",
    "                        cbar=False, ax=ax,\n",
    "                        xticklabels=x,\n",
    "                        yticklabels=y)\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Encoder Layer\", layer + 1)\n",
    "        for h in range(4):\n",
    "            draw(enc_attns[layer][0, h, :len(src), :len(src)], axs[h], src, src)\n",
    "        plt.show()\n",
    "        \n",
    "    for layer in range(0, 2, 1):\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        print(\"Decoder Self Layer\", layer+1)\n",
    "        for h in range(4):\n",
    "            draw(dec_attns[layer][0, h, :len(tgt), :len(tgt)], axs[h], tgt, tgt)\n",
    "        plt.show()\n",
    "\n",
    "        print(\"Decoder Src Layer\", layer+1)\n",
    "        fig, axs = plt.subplots(1, 4, figsize=(20, 10))\n",
    "        for h in range(4):\n",
    "            draw(dec_enc_attns[layer][0, h, :len(tgt), :len(src)], axs[h], src, tgt)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad19d391",
   "metadata": {},
   "source": [
    "## 번역생성함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a9001eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 함수\n",
    "def evaluate(sentence, model, src_tokenizer, tgt_tokenizer):\n",
    "    sentence = preprocess_sentence(sentence)\n",
    "    pieces = src_tokenizer.encode_as_pieces(sentence)\n",
    "    tokens = src_tokenizer.encode_as_ids(sentence)\n",
    "\n",
    "    _input = tf.keras.preprocessing.sequence.pad_sequences([tokens], maxlen=enc_train.shape[-1], padding='post')\n",
    "\n",
    "    ids = []\n",
    "    output = tf.expand_dims([tgt_tokenizer.bos_id()], 0)\n",
    "    for i in range(dec_train.shape[-1]):\n",
    "        enc_padding_mask, combined_mask, dec_padding_mask = generate_masks(_input, output)\n",
    "        \n",
    "\n",
    "        predictions, enc_attns, dec_attns, dec_enc_attns = model(_input, output, enc_padding_mask, combined_mask, dec_padding_mask)\n",
    "        \n",
    "        predicted_id = tf.argmax(tf.math.softmax(predictions, axis=-1)[0, -1]).numpy().item()\n",
    "        if tgt_tokenizer.eos_id() == predicted_id:\n",
    "            result = tgt_tokenizer.decode_ids(ids)\n",
    "            return pieces, result, enc_attns, dec_attns, dec_enc_attns\n",
    "\n",
    "        ids.append(predicted_id)\n",
    "        output = tf.concat([output, tf.expand_dims([predicted_id], 0)], axis=-1)\n",
    "    result = tgt_tokenizer.decode_ids(ids)\n",
    "    return pieces, result, enc_attns, dec_attns, dec_enc_attns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e82cc899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 번역 생성 및 Attention 시각화 결합\n",
    "def translate(sentence, model, src_tokenizer, tgt_tokenizer, plot_attention=False):\n",
    "    pieces, result, enc_attns, dec_attns, dec_enc_attns = evaluate(sentence, model, src_tokenizer, tgt_tokenizer)\n",
    "    \n",
    "    print('Input: %s' % (sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    if plot_attention:\n",
    "        visualize_attention(pieces, result.split(), enc_attns, dec_attns, dec_enc_attns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "294d6047",
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = [\n",
    "    \"How was your day? I was the best.\",\n",
    "    \"Take your time, please.\",\n",
    "    \"I’m about to leave. Please hold for a moment.\",\n",
    "    \"Have you heard of it?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e2c832",
   "metadata": {},
   "source": [
    "## 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7d2f9ed6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 학습\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "def train_and_checkpoint(transformer, manager, EPOCHS):\n",
    "    ckpt.restore(manager.latest_checkpoint)\n",
    "    if manager.latest_checkpoint:\n",
    "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "    \n",
    "    else:\n",
    "        print(\"Initializing from scratch.\")\n",
    "\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        total_loss = 0\n",
    "\n",
    "        idx_list = list(range(0, enc_train.shape[0], BATCH_SIZE))\n",
    "        random.shuffle(idx_list)\n",
    "        t = tqdm(idx_list)\n",
    "\n",
    "        for (batch, idx) in enumerate(t):\n",
    "            batch_loss, enc_attns, dec_attns, dec_enc_attns = train_step(enc_train[idx:idx+BATCH_SIZE],\n",
    "                                                                         dec_train[idx:idx+BATCH_SIZE],\n",
    "                                                                         transformer,\n",
    "                                                                         optimizer)\n",
    "\n",
    "            total_loss += batch_loss\n",
    "\n",
    "            t.set_description_str('Epoch %2d' % (epoch + 1))\n",
    "            t.set_postfix_str('Loss %.4f' % (total_loss.numpy() / (batch + 1)))\n",
    "      \n",
    "      \n",
    "        # 매 Epoch 마다 제시된 예문에 대한 번역 생성\n",
    "        for example in examples:\n",
    "            translate(example, transformer, en_tokenizer, ko_tokenizer)\n",
    "            \n",
    " \n",
    "        if int(ckpt.step) % 2 == 0:\n",
    "            save_path = manager.save()\n",
    "            print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "699c035e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing from scratch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "126770440af64e869805825e24ae59f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How was your day? I was the best.\n",
      "Predicted translation: 그는 나는 나는 나는 나는 내가 ?\n",
      "Input: Take your time, please.\n",
      "Predicted translation: .\n",
      "Input: I’m about to leave. Please hold for a moment.\n",
      "Predicted translation: 그는 또 다른 나라를 통해 나는 내가 됐다 .\n",
      "Input: Have you heard of it?\n",
      "Predicted translation: 이 같은 사람들은 ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "602bb92985a94c2c869df3185b1d25ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How was your day? I was the best.\n",
      "Predicted translation: 당신은 당신의 당신의 말을 인용 , 당신은 당신의 생명을  ⁇ 니다 .\n",
      "Input: Take your time, please.\n",
      "Predicted translation: 당신은 당신에게 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 당신을 함께 한다 .\n",
      "Input: I’m about to leave. Please hold for a moment.\n",
      "Predicted translation: 나는 나는 그가 나를 뽑는 것을 촉구한다 .\n",
      "Input: Have you heard of it?\n",
      "Predicted translation: 그는 당신의 말을 잊지 않는다\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ceeeac76914dd7841419a27cc64248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How was your day? I was the best.\n",
      "Predicted translation: 어떻게 어떻게 어떻게 날을 할 것인가 ?\n",
      "Input: Take your time, please.\n",
      "Predicted translation: 당신에게 당신에게 당신에게 당신에게 당신을 방문했다 .\n",
      "Input: I’m about to leave. Please hold for a moment.\n",
      "Predicted translation: 저는 나는 이 자리에 오르기 위해 일을 했다 .\n",
      "Input: Have you heard of it?\n",
      "Predicted translation: 내가 당신의 말을 인용해 ?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f388788e6c042a7bc690efdc651d9f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How was your day? I was the best.\n",
      "Predicted translation: 그는 가장 잘 알려진 것 같다 고 말했다 .\n",
      "Input: Take your time, please.\n",
      "Predicted translation: 당신에게 당신에게 당신에게 당신에게 당신에게 당신에게 당신을 주게 된다 .\n",
      "Input: I’m about to leave. Please hold for a moment.\n",
      "Predicted translation: 그는 또 나는 이 일을 기다 .\n",
      "Input: Have you heard of it?\n",
      "Predicted translation: 내가 찾은 검색어\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef6422e49b41278f2d89b026aa8af7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1202 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: How was your day? I was the best.\n",
      "Predicted translation: 어떻게 처리가 있는지 판단하기가 ?\n",
      "Input: Take your time, please.\n",
      "Predicted translation: 자녀들을 데리고 오는 월 일 개봉한다 .\n",
      "Input: I’m about to leave. Please hold for a moment.\n",
      "Predicted translation: 그는 종료 후 은퇴를 선언했다 .\n",
      "Input: Have you heard of it?\n",
      "Predicted translation: 내가  ⁇ 는 소리가 ?\n"
     ]
    }
   ],
   "source": [
    "train_and_checkpoint(transformer, manager, EPOCHS )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ec9ade7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Jupiter is surrounded by a shell of invisible but extremely dangerous high-energy charged particles.\n",
      "Predicted translation: 소행성은 위험하고 있는 위험한 도시다 라 불리는 방출량을 겪게 되었다 .\n",
      "Input: The spacecraft must pass through the outer edge of this radiation belt to examine Jupiter and its moons close up, and to continue its mission to Saturn and beyond.\n",
      "Predicted translation: 탐사선은 우주선이 대기권을 통과하는데 신중하게 대응해 줄 것을 요구해 왔다 .\n",
      "Input: But the charged particles can damage the delicate instruments and fry the electronics.\n",
      "Predicted translation: 그러나 이 현상은  ⁇ 기 , 및 컴퓨터를 사용하여  ⁇ 통으로  ⁇ 겨져있다 .\n"
     ]
    }
   ],
   "source": [
    "examples = [\n",
    "\n",
    "    \"Jupiter is surrounded by a shell of invisible but extremely dangerous high-energy charged particles.\",\n",
    "    \"The spacecraft must pass through the outer edge of this radiation belt to examine Jupiter and its moons close up, and to continue its mission to Saturn and beyond.\", \n",
    "    \"But the charged particles can damage the delicate instruments and fry the electronics.\" \n",
    "]\n",
    "\n",
    "for example in examples:\n",
    "    translate(example, transformer, en_tokenizer, ko_tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2f64eb",
   "metadata": {},
   "source": [
    "# Step 5. 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "386ff965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96bda3a27e774bbcb3122ab8b43661a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.49k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52f3ffbae7d94af291170251b7b009ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'bleu': 0.0,\n",
       " 'precisions': [0.8, 0.5, 0.3333333333333333, 0.0],\n",
       " 'brevity_penalty': 1.0,\n",
       " 'length_ratio': 1.25,\n",
       " 'translation_length': 5,\n",
       " 'reference_length': 4}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bleu example\n",
    "from datasets import load_metric\n",
    "\n",
    "bleu = load_metric(\"bleu\")\n",
    "predictions = [[\"I\", \"have\", \"thirty\", \"six\", \"years\"]] \n",
    "references = [\n",
    "    [[\"I\", \"am\", \"thirty\", \"six\", \"years\", \"old\"], [\"I\", \"am\", \"thirty\", \"six\"]]\n",
    "]\n",
    "bleu.compute(predictions=predictions, references=references)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c03400",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd603a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a073b883",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005a7fd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    " \n",
    "import matplotlib.font_manager as fm\n",
    "\n",
    "fontpath = '/usr/share/fonts/truetype/nanum/NanumBarunGothic.ttf'\n",
    "font = fm.FontProperties(fname=fontpath, size=9)\n",
    "plt.rc('font', family='NanumBarunGothic') \n",
    "# mpl.font_manager._rebuild()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58adfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 매 Epoch 마다 제시된 예문에 대한 번역 생성시각화\n",
    "# for example in examples:\n",
    "#     translate(example, transformer, en_tokenizer, ko_tokenizer, plot_attention=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0bb8151",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5966a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
